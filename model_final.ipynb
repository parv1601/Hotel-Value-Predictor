{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba6fae0c",
      "metadata": {
        "id": "ba6fae0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9ab8aa",
      "metadata": {
        "id": "ad9ab8aa"
      },
      "source": [
        "Helper function to convert Log RMSE back to RMSE\n",
        "\n",
        "Reverse log transform (np.expm1 is the inverse of np.log1p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48a3625a",
      "metadata": {
        "id": "48a3625a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rmse_from_log_rmse(y_true_log, y_pred_log):\n",
        "\n",
        "    y_true = np.expm1(y_true_log)\n",
        "    y_pred = np.expm1(y_pred_log)\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ddf679c",
      "metadata": {
        "id": "5ddf679c"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "660f8f5d",
      "metadata": {
        "id": "660f8f5d"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('final_processed_train.csv')\n",
        "X_test = pd.read_csv('final_processed_test.csv')\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "y_train_log = X_train['HotelValue_Log']\n",
        "X_train.drop(columns=['HotelValue_Log'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb441efa",
      "metadata": {
        "id": "bb441efa"
      },
      "source": [
        "5 Fold cross validation is standard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8e98ef68",
      "metadata": {
        "id": "8e98ef68"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4030022a",
      "metadata": {
        "id": "4030022a"
      },
      "source": [
        "Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86474bcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86474bcb",
        "outputId": "2e486d8b-3d1b-4f20-e462-d53fa787cceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "--- OLS Baseline Complete ---\n",
            "OLS - Cross-Validation Log RMSE: 0.1222\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the model (OLS has no hyperparameters to tune)\n",
        "ols_model = LinearRegression(n_jobs=-1)\n",
        "\n",
        "# The parameter grid is empty since OLS has no tuning parameters.\n",
        "# GridSearchCV will simply use the model as-is across all CV folds.\n",
        "param_grid_ols = {}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "ols_grid_search = GridSearchCV(\n",
        "    estimator=ols_model,\n",
        "    param_grid=param_grid_ols,  # Empty grid just runs the model once per CV fold\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the OLS baseline test\n",
        "ols_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_ols = ols_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-ols_grid_search.best_score_)\n",
        "print('\\n--- OLS Baseline Complete ---')\n",
        "print(f\"OLS - Cross-Validation Log RMSE: {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75021708",
      "metadata": {
        "id": "75021708"
      },
      "source": [
        "Ridge Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85bfde99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85bfde99",
        "outputId": "680bc261-1389-428e-9b1c-a771a2c36d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "--- Ridge Fine-Tuning Complete ---\n",
            "Ridge - Best Alpha (Grid): 211.1111\n",
            "Ridge - Best Log RMSE (Grid CV): 0.1134\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "ridge = Ridge(random_state=42)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# We focus the search around the best alpha of 215.4435\n",
        "param_grid_ridge_fine = {\n",
        "    # Creating 10 steps for alpha between 100 and 300\n",
        "    'alpha': np.linspace(100, 300, 10)\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    estimator=ridge,\n",
        "    param_grid=param_grid_ridge_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "# X_train and y_train_log are the scaled features and log target\n",
        "ridge_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_ridge = ridge_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-ridge_grid_search.best_score_)\n",
        "print('\\n--- Ridge Fine-Tuning Complete ---')\n",
        "print(f\"Ridge - Best Alpha (Grid): {ridge_grid_search.best_params_['alpha']:.4f}\")\n",
        "print(f\"Ridge - Best Log RMSE (Grid CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acee4653",
      "metadata": {
        "id": "acee4653"
      },
      "source": [
        "LASSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e8ab77e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ab77e0",
        "outputId": "18a904ea-d000-4f5e-d825-d1f6e3759f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "--- Lasso Fine-Tuning Complete ---\n",
            "Lasso - Best Alpha (Grid): 0.003000\n",
            "Lasso - Best Log RMSE (Grid CV): 0.1081\n"
          ]
        }
      ],
      "source": [
        "# Define the model and set max_iter high for convergence\n",
        "lasso = Lasso(random_state=42, max_iter=5000)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# Focusing the search around the best alpha of 0.002069\n",
        "param_grid_lasso_fine = {\n",
        "    # Creating 10 steps for alpha between 0.001 and 0.003\n",
        "    'alpha': np.linspace(0.001, 0.003, 10)\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "lasso_grid_search = GridSearchCV(\n",
        "    estimator=lasso,\n",
        "    param_grid=param_grid_lasso_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "# X_train and y_train_log are the scaled features and log target\n",
        "lasso_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_lasso = lasso_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-lasso_grid_search.best_score_)\n",
        "print('\\n--- Lasso Fine-Tuning Complete ---')\n",
        "print(f\"Lasso - Best Alpha (Grid): {lasso_grid_search.best_params_['alpha']:.6f}\")\n",
        "print(f\"Lasso - Best Log RMSE (Grid CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92728c5",
      "metadata": {
        "id": "f92728c5"
      },
      "source": [
        "Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6132e08e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6132e08e",
        "outputId": "e32bdd26-0ddd-41a9-f49e-bfba47bf8c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "--- ElasticNet Fine-Tuning Complete ---\n",
            "ElasticNet - Best Parameters (Grid): {'alpha': np.float64(0.02333333333333333), 'l1_ratio': 0.15}\n",
            "ElasticNet - Best Log RMSE (Grid CV): 0.1078 \n"
          ]
        }
      ],
      "source": [
        "# Initialize the model with max_iter for convergence\n",
        "elastic_net = ElasticNet(random_state=42, max_iter=5000)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# We focus the search around the best alpha (0.0215) and keep l1_ratio close to 0.1\n",
        "param_grid_elastic_fine = {\n",
        "    # Narrow range for alpha around 0.0215\n",
        "    'alpha': np.linspace(0.01, 0.04, 10),\n",
        "    # Narrow range for l1_ratio around 0.1\n",
        "    'l1_ratio': [0.05, 0.1, 0.15]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "elastic_grid_search = GridSearchCV(\n",
        "    estimator=elastic_net,\n",
        "    param_grid=param_grid_elastic_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "elastic_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_elastic = elastic_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-elastic_grid_search.best_score_)\n",
        "print('\\n--- ElasticNet Fine-Tuning Complete ---')\n",
        "print(f'ElasticNet - Best Parameters (Grid): {elastic_grid_search.best_params_}')\n",
        "print(f'ElasticNet - Best Log RMSE (Grid CV): {best_score:.4f} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a1471a",
      "metadata": {
        "id": "27a1471a"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1ee19630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ee19630",
        "outputId": "b8fa61c2-e63b-4599-871f-f1c3b2787287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "\n",
            "--- Random Forest Fine-Tuning Complete ---\n",
            "Random Forest - Best Parameters (Grid): {'max_depth': 16, 'min_samples_leaf': 1, 'n_estimators': 350}\n",
            "Random Forest - Best Log RMSE (Grid CV): 0.1266\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "# Use a reasonable base based on what RandomizedSearch may have suggested\n",
        "random_forest = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# These values should be based on the best results from your prior RandomizedSearchCV\n",
        "param_grid_rf_fine = {\n",
        "    # Check around the best n_estimators (e.g., 250, 300, 350)\n",
        "    'n_estimators': [250, 300, 350],\n",
        "    # Check slightly above and below the best max_depth\n",
        "    'max_depth': [12, 14, 16],\n",
        "    # Fine-tune min_samples_leaf\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=random_forest,\n",
        "    param_grid=param_grid_rf_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "rf_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-rf_grid_search.best_score_)\n",
        "print('\\n--- Random Forest Fine-Tuning Complete ---')\n",
        "print(f'Random Forest - Best Parameters (Grid): {rf_grid_search.best_params_}')\n",
        "print(f'Random Forest - Best Log RMSE (Grid CV): {best_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c82057",
      "metadata": {
        "id": "04c82057"
      },
      "source": [
        "XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "30d3967c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30d3967c",
        "outputId": "5f7c886e-fb03-45aa-9ec6-1d792ed49ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "\n",
            "--- XGBoost Fine-Tuning Complete ---\n",
            "XGBoost - Best Parameters (Grid): {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 700}\n",
            "XGBoost - Best Log RMSE (Grid CV): 0.1135\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model with good default parameters\n",
        "# Use 'gbtree' booster which is standard tree-based model\n",
        "xgb_model = XGBRegressor(random_state=42, booster='gbtree', n_jobs=-1)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# These values should be based on the best results from your prior RandomizedSearchCV\n",
        "param_grid_xgb_fine = {\n",
        "    # Check around the best learning rate\n",
        "    'learning_rate': [0.03, 0.05, 0.07],\n",
        "    # Check around the best tree complexity\n",
        "    'max_depth': [3, 4, 5],\n",
        "    # Check around the best number of trees\n",
        "    'n_estimators': [500, 600, 700]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "xgb_grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid_xgb_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "xgb_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_xgb = xgb_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-xgb_grid_search.best_score_)\n",
        "print('\\n--- XGBoost Fine-Tuning Complete ---')\n",
        "print(f'XGBoost - Best Parameters (Grid): {xgb_grid_search.best_params_}')\n",
        "print(f'XGBoost - Best Log RMSE (Grid CV): {best_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7AhvHAvXue8w",
      "metadata": {
        "id": "7AhvHAvXue8w"
      },
      "source": [
        "Lasso Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Zbhl9WsVuSZE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbhl9WsVuSZE",
        "outputId": "f6b96907-65c0-4ce8-e3a8-69193f799ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned Lasso Model...\n",
            "\n",
            "--- Submission File Created ---\n",
            "File Name: submission_lasso_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  151324.515321\n",
            "1  1106  326795.295705\n",
            "2   414  106447.127882\n",
            "3   523  156977.966693\n",
            "4  1037  292659.232959\n"
          ]
        }
      ],
      "source": [
        "# --- 10. Final Prediction and Submission (Corrected) ---\n",
        "print('\\nStarting Final Prediction using Tuned Lasso Model...')\n",
        "from sklearn.linear_model import Lasso\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD THE IDs from the original RAW test file\n",
        "# This file is guaranteed to have the original 'Id' column.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features without 'Id'\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best Lasso model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_lasso' was defined and trained in a previous cell.\n",
        "final_lasso_model = best_lasso\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_lasso_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_lasso_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created ---\")\n",
        "print(\"File Name: submission_lasso_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s0TKBNfEuxQ8",
      "metadata": {
        "id": "s0TKBNfEuxQ8"
      },
      "source": [
        "Linear Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "_uslj9Jwu5Dg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uslj9Jwu5Dg",
        "outputId": "05136226-84c3-45d3-8858-032ca68d24d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using OLS Linear Regression Model...\n",
            "\n",
            "--- OLS Submission File Created ---\n",
            "File Name: submission_ols_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  151343.562522\n",
            "1  1106  341336.599794\n",
            "2   414  101185.942667\n",
            "3   523  166420.682297\n",
            "4  1037  300134.214359\n"
          ]
        }
      ],
      "source": [
        "# --- 11. Final Prediction and Submission (OLS) ---\n",
        "print('\\nStarting Final Prediction using OLS Linear Regression Model...')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best OLS model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_ols' was defined and trained in a previous cell.\n",
        "final_ols_model = best_ols\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_ols_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_ols_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- OLS Submission File Created ---\")\n",
        "print(\"File Name: submission_ols_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N9jInIF0xEU6",
      "metadata": {
        "id": "N9jInIF0xEU6"
      },
      "source": [
        "xgBoost Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9qx6PdmrxGoc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qx6PdmrxGoc",
        "outputId": "4fc2227c-30c4-41ef-89bf-f966887ec563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned XGBoost Model...\n",
            "\n",
            "--- XGBoost Submission File Created ---\n",
            "File Name: submission_xgb_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  148385.640625\n",
            "1  1106  346520.500000\n",
            "2   414  102781.953125\n",
            "3   523  156082.156250\n",
            "4  1037  336281.250000\n"
          ]
        }
      ],
      "source": [
        "# --- 14. Final Prediction and Submission (XGBoost) ---\n",
        "print('\\nStarting Final Prediction using Tuned XGBoost Model...')\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best XGBoost model found by GridSearchCV/RandomizedSearchCV\n",
        "# NOTE: This assumes the variable 'best_xgb' was defined and trained in a previous cell.\n",
        "final_xgb_model = best_xgb\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_xgb_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_xgb_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- XGBoost Submission File Created ---\")\n",
        "print(\"File Name: submission_xgb_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-DCo8nGFyEUL",
      "metadata": {
        "id": "-DCo8nGFyEUL"
      },
      "source": [
        "Elastic net Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "kgENdxbFyJVR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgENdxbFyJVR",
        "outputId": "9d99613f-0699-41ee-9315-300b6365c965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned ElasticNet Model...\n",
            "\n",
            "--- ElasticNet Submission File Created ---\n",
            "File Name: submission_elastic_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  150333.617267\n",
            "1  1106  324441.623139\n",
            "2   414  107186.999218\n",
            "3   523  155746.235155\n",
            "4  1037  293219.443373\n"
          ]
        }
      ],
      "source": [
        "# --- 15. Final Prediction and Submission (ElasticNet) ---\n",
        "print('\\nStarting Final Prediction using Tuned ElasticNet Model...')\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best ElasticNet model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_elastic' was defined and trained in a previous cell.\n",
        "final_elastic_model = best_elastic\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_elastic_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_elastic_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- ElasticNet Submission File Created ---\")\n",
        "print(\"File Name: submission_elastic_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Submission"
      ],
      "metadata": {
        "id": "Aw_j-OvfkIZG"
      },
      "id": "Aw_j-OvfkIZG"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Final Prediction and Submission using Tuned Ridge Model ---\n",
        "print('\\nStarting Final Prediction using Tuned Ridge Model...')\n",
        "from sklearn.linear_model import Ridge # Import the Ridge model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This file is guaranteed to have the original 'Id' column.\n",
        "# NOTE: Ensure 'test.csv' is available in the current directory.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features without 'Id'\n",
        "# NOTE: Ensure 'final_processed_test.csv' is available and contains the correct features.\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True) # Assuming NaN imputation strategy is 0\n",
        "\n",
        "# 3. Use the best Ridge model found by GridSearchCV/RandomizedSearchCV\n",
        "# IMPORTANT: This assumes a variable named 'best_ridge' was defined and trained\n",
        "# in a preceding step (e.g., using a cross-validation script).\n",
        "# Replace 'best_ridge' with your actual best model variable name if different.\n",
        "final_ridge_model = best_ridge\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_ridge_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative, as HotelValue cannot be less than zero\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_ridge_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created ---\")\n",
        "print(\"File Name: submission_ridge_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjAfcHlhkKuD",
        "outputId": "4702702a-aaf0-4c27-dc97-0bcec18c74e9"
      },
      "id": "yjAfcHlhkKuD",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned Ridge Model...\n",
            "\n",
            "--- Submission File Created ---\n",
            "File Name: submission_ridge_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  147277.722743\n",
            "1  1106  324375.355492\n",
            "2   414  102665.984532\n",
            "3   523  156372.304749\n",
            "4  1037  295728.816615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Submission"
      ],
      "metadata": {
        "id": "tjDjkQm6kmJj"
      },
      "id": "tjDjkQm6kmJj"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Final Prediction and Submission using Tuned Random Forest Model ---\n",
        "print('\\nStarting Final Prediction using Tuned Random Forest Model...')\n",
        "from sklearn.ensemble import RandomForestRegressor # Import the Random Forest Regressor model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This file is guaranteed to have the original 'Id' column.\n",
        "# NOTE: Ensure 'test.csv' is available in the current directory.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features without 'Id'\n",
        "# NOTE: Ensure 'final_processed_test.csv' is available and contains the correct features.\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True) # Assuming NaN imputation strategy is 0\n",
        "\n",
        "# 3. Use the best Random Forest model found by GridSearchCV/RandomizedSearchCV\n",
        "# IMPORTANT: This assumes a variable named 'best_rf' was defined and trained\n",
        "# in a preceding step (e.g., using a cross-validation script).\n",
        "# Replace 'best_rf' with your actual best model variable name if different.\n",
        "final_rf_model = best_rf\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_rf_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative, as HotelValue cannot be less than zero\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_rf_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created ---\")\n",
        "print(\"File Name: submission_rf_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzElnbA2kpPD",
        "outputId": "adf5799d-01ea-47f9-cc51-155213082cce"
      },
      "id": "SzElnbA2kpPD",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned Random Forest Model...\n",
            "\n",
            "--- Submission File Created ---\n",
            "File Name: submission_rf_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  143329.964509\n",
            "1  1106  321564.227682\n",
            "2   414  109989.776342\n",
            "3   523  154115.632842\n",
            "4  1037  299901.453113\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}