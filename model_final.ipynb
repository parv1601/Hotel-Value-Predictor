{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba6fae0c",
      "metadata": {
        "id": "ba6fae0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9ab8aa",
      "metadata": {
        "id": "ad9ab8aa"
      },
      "source": [
        "Helper function to convert Log RMSE back to RMSE\n",
        "\n",
        "Reverse log transform (np.expm1 is the inverse of np.log1p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a3625a",
      "metadata": {
        "id": "48a3625a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rmse_from_log_rmse(y_true_log, y_pred_log):\n",
        "\n",
        "    y_true = np.expm1(y_true_log)\n",
        "    y_pred = np.expm1(y_pred_log)\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ddf679c",
      "metadata": {
        "id": "5ddf679c"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660f8f5d",
      "metadata": {
        "id": "660f8f5d"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('final_processed_train.csv')\n",
        "X_test = pd.read_csv('final_processed_test.csv')\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "y_train_log = X_train['HotelValue_Log']\n",
        "X_train.drop(columns=['HotelValue_Log'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb441efa",
      "metadata": {
        "id": "bb441efa"
      },
      "source": [
        "5 Fold cross validation is standard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8e98ef68",
      "metadata": {
        "id": "8e98ef68"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4030022a",
      "metadata": {
        "id": "4030022a"
      },
      "source": [
        "Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "86474bcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86474bcb",
        "outputId": "af3337ae-d071-4341-ff4e-d6f8bd34d5ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py\", line 618, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1368, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/pandas/core/generic.py\", line 2171, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\\twith 61 stored elements and shape (1, 208)>\\n  Coords\\tValues\\n  (0, 0)\\t-0.8668603157359984\\n  (0, 1)\\t1.7733049393584983\\n  (0, 2)\\t0.334828231773507\\n  (0, 3)\\t1.581885422218427\\n  (0, 4)\\t1.035027587483188\\n  (0, 5)\\t-0.24126099324259317\\n  (0, 6)\\t0.10516582156994889\\n  (0, 7)\\t1.2984710857212116\\n  (0, 8)\\t3.045855817504199\\n  (0, 9)\\t1.9777946679677483\\n  (0, 10)\\t-0.1375819689808867\\n  (0, 11)\\t-0.11742874694013619\\n  (0, 12)\\t0.8595129082267801\\n  (0, 13)\\t0.14613745260615033\\n  (0, 14)\\t-0.21200287527178915\\n  (0, 15)\\t0.7329087780615434\\n  (0, 16)\\t1.5168878881904044\\n  (0, 17)\\t0.24037768460272918\\n  (0, 18)\\t0.5933153904668956\\n  (0, 19)\\t1.1265733108713836\\n  (0, 20)\\t1.4260631244641435\\n  (0, 21)\\t1.6447524072366042\\n  (0, 22)\\t0.25461983642529346\\n  (0, 23)\\t0.2600035511596441\\n  (0, 24)\\t-0.09152341037077903\\n  :\\t:\\n  (0, 39)\\t1.0\\n  (0, 42)\\t1.0\\n  (0, 46)\\t1.0\\n  (0, 50)\\t1.0\\n  (0, 51)\\t1.0\\n  (0, 53)\\t1.0\\n  (0, 58)\\t1.0\\n  (0, 77)\\t1.0\\n  (0, 88)\\t1.0\\n  (0, 97)\\t1.0\\n  (0, 103)\\t1.0\\n  (0, 110)\\t1.0\\n  (0, 119)\\t1.0\\n  (0, 123)\\t1.0\\n  (0, 141)\\t1.0\\n  (0, 157)\\t1.0\\n  (0, 162)\\t1.0\\n  (0, 168)\\t1.0\\n  (0, 172)\\t1.0\\n  (0, 178)\\t1.0\\n  (0, 182)\\t1.0\\n  (0, 184)\\t1.0\\n  (0, 192)\\t1.0\\n  (0, 199)\\t1.0\\n  (0, 207)\\t1.0\"\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py\", line 618, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1368, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/pandas/core/generic.py\", line 2171, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\\twith 61 stored elements and shape (1, 208)>\\n  Coords\\tValues\\n  (0, 0)\\t-0.8668603157359984\\n  (0, 1)\\t-0.00817191216294246\\n  (0, 2)\\t0.05517656044338374\\n  (0, 3)\\t-0.5984678858090774\\n  (0, 4)\\t1.035027587483188\\n  (0, 5)\\t-0.24126099324259317\\n  (0, 6)\\t0.10516582156994889\\n  (0, 7)\\t-0.5897846229261294\\n  (0, 8)\\t-0.2894539429565385\\n  (0, 9)\\t0.32863034023422283\\n  (0, 10)\\t-1.1750711564531044\\n  (0, 11)\\t-0.11742874694013619\\n  (0, 12)\\t-0.607573060375017\\n  (0, 13)\\t0.14613745260615033\\n  (0, 14)\\t-0.21200287527178915\\n  (0, 15)\\t-0.7718131823764544\\n  (0, 16)\\t-0.34024136089771173\\n  (0, 17)\\t0.24037768460272918\\n  (0, 18)\\t0.5933153904668956\\n  (0, 19)\\t-0.0818820521491004\\n  (0, 20)\\t0.3063187326943281\\n  (0, 21)\\t0.2912464797989319\\n  (0, 22)\\t0.25461983642529346\\n  (0, 23)\\t0.2600035511596441\\n  (0, 24)\\t-0.09152341037077903\\n  :\\t:\\n  (0, 39)\\t1.0\\n  (0, 42)\\t1.0\\n  (0, 43)\\t1.0\\n  (0, 50)\\t1.0\\n  (0, 51)\\t1.0\\n  (0, 57)\\t1.0\\n  (0, 58)\\t1.0\\n  (0, 85)\\t1.0\\n  (0, 88)\\t1.0\\n  (0, 97)\\t1.0\\n  (0, 103)\\t1.0\\n  (0, 110)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 123)\\t1.0\\n  (0, 138)\\t1.0\\n  (0, 154)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 168)\\t1.0\\n  (0, 172)\\t1.0\\n  (0, 178)\\t1.0\\n  (0, 182)\\t1.0\\n  (0, 184)\\t1.0\\n  (0, 192)\\t1.0\\n  (0, 201)\\t1.0\\n  (0, 206)\\t1.0\"\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      9\u001b[39m ols_grid_search = GridSearchCV(\n\u001b[32m     10\u001b[39m     estimator=ols_model,\n\u001b[32m     11\u001b[39m     param_grid=param_grid_ols,  \u001b[38;5;66;03m# Empty grid just runs the model once per CV fold\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Run the OLS baseline test\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mols_grid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Output Results\u001b[39;00m\n\u001b[32m     22\u001b[39m best_ols = ols_grid_search.best_estimator_\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py\", line 618, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1368, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/pandas/core/generic.py\", line 2171, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\\twith 61 stored elements and shape (1, 208)>\\n  Coords\\tValues\\n  (0, 0)\\t-0.8668603157359984\\n  (0, 1)\\t1.7733049393584983\\n  (0, 2)\\t0.334828231773507\\n  (0, 3)\\t1.581885422218427\\n  (0, 4)\\t1.035027587483188\\n  (0, 5)\\t-0.24126099324259317\\n  (0, 6)\\t0.10516582156994889\\n  (0, 7)\\t1.2984710857212116\\n  (0, 8)\\t3.045855817504199\\n  (0, 9)\\t1.9777946679677483\\n  (0, 10)\\t-0.1375819689808867\\n  (0, 11)\\t-0.11742874694013619\\n  (0, 12)\\t0.8595129082267801\\n  (0, 13)\\t0.14613745260615033\\n  (0, 14)\\t-0.21200287527178915\\n  (0, 15)\\t0.7329087780615434\\n  (0, 16)\\t1.5168878881904044\\n  (0, 17)\\t0.24037768460272918\\n  (0, 18)\\t0.5933153904668956\\n  (0, 19)\\t1.1265733108713836\\n  (0, 20)\\t1.4260631244641435\\n  (0, 21)\\t1.6447524072366042\\n  (0, 22)\\t0.25461983642529346\\n  (0, 23)\\t0.2600035511596441\\n  (0, 24)\\t-0.09152341037077903\\n  :\\t:\\n  (0, 39)\\t1.0\\n  (0, 42)\\t1.0\\n  (0, 46)\\t1.0\\n  (0, 50)\\t1.0\\n  (0, 51)\\t1.0\\n  (0, 53)\\t1.0\\n  (0, 58)\\t1.0\\n  (0, 77)\\t1.0\\n  (0, 88)\\t1.0\\n  (0, 97)\\t1.0\\n  (0, 103)\\t1.0\\n  (0, 110)\\t1.0\\n  (0, 119)\\t1.0\\n  (0, 123)\\t1.0\\n  (0, 141)\\t1.0\\n  (0, 157)\\t1.0\\n  (0, 162)\\t1.0\\n  (0, 168)\\t1.0\\n  (0, 172)\\t1.0\\n  (0, 178)\\t1.0\\n  (0, 182)\\t1.0\\n  (0, 184)\\t1.0\\n  (0, 192)\\t1.0\\n  (0, 199)\\t1.0\\n  (0, 207)\\t1.0\"\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/linear_model/_base.py\", line 618, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1368, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/parv/miniconda3/envs/ml_env/lib/python3.11/site-packages/pandas/core/generic.py\", line 2171, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: \"<Compressed Sparse Row sparse matrix of dtype 'float64'\\n\\twith 61 stored elements and shape (1, 208)>\\n  Coords\\tValues\\n  (0, 0)\\t-0.8668603157359984\\n  (0, 1)\\t-0.00817191216294246\\n  (0, 2)\\t0.05517656044338374\\n  (0, 3)\\t-0.5984678858090774\\n  (0, 4)\\t1.035027587483188\\n  (0, 5)\\t-0.24126099324259317\\n  (0, 6)\\t0.10516582156994889\\n  (0, 7)\\t-0.5897846229261294\\n  (0, 8)\\t-0.2894539429565385\\n  (0, 9)\\t0.32863034023422283\\n  (0, 10)\\t-1.1750711564531044\\n  (0, 11)\\t-0.11742874694013619\\n  (0, 12)\\t-0.607573060375017\\n  (0, 13)\\t0.14613745260615033\\n  (0, 14)\\t-0.21200287527178915\\n  (0, 15)\\t-0.7718131823764544\\n  (0, 16)\\t-0.34024136089771173\\n  (0, 17)\\t0.24037768460272918\\n  (0, 18)\\t0.5933153904668956\\n  (0, 19)\\t-0.0818820521491004\\n  (0, 20)\\t0.3063187326943281\\n  (0, 21)\\t0.2912464797989319\\n  (0, 22)\\t0.25461983642529346\\n  (0, 23)\\t0.2600035511596441\\n  (0, 24)\\t-0.09152341037077903\\n  :\\t:\\n  (0, 39)\\t1.0\\n  (0, 42)\\t1.0\\n  (0, 43)\\t1.0\\n  (0, 50)\\t1.0\\n  (0, 51)\\t1.0\\n  (0, 57)\\t1.0\\n  (0, 58)\\t1.0\\n  (0, 85)\\t1.0\\n  (0, 88)\\t1.0\\n  (0, 97)\\t1.0\\n  (0, 103)\\t1.0\\n  (0, 110)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 123)\\t1.0\\n  (0, 138)\\t1.0\\n  (0, 154)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 168)\\t1.0\\n  (0, 172)\\t1.0\\n  (0, 178)\\t1.0\\n  (0, 182)\\t1.0\\n  (0, 184)\\t1.0\\n  (0, 192)\\t1.0\\n  (0, 201)\\t1.0\\n  (0, 206)\\t1.0\"\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the model (OLS has no hyperparameters to tune)\n",
        "ols_model = LinearRegression(n_jobs=-1)\n",
        "\n",
        "# The parameter grid is empty since OLS has no tuning parameters.\n",
        "# GridSearchCV will simply use the model as-is across all CV folds.\n",
        "param_grid_ols = {}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "ols_grid_search = GridSearchCV(\n",
        "    estimator=ols_model,\n",
        "    param_grid=param_grid_ols,  # Empty grid just runs the model once per CV fold\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the OLS baseline test\n",
        "ols_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_ols = ols_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-ols_grid_search.best_score_)\n",
        "print('\\n--- OLS Baseline Complete ---')\n",
        "print(f\"OLS - Cross-Validation Log RMSE: {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75021708",
      "metadata": {
        "id": "75021708"
      },
      "source": [
        "Ridge Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85bfde99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85bfde99",
        "outputId": "48511f06-58f9-45ff-8713-4abfacb1ea00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "--- Ridge Fine-Tuning Complete ---\n",
            "Ridge - Best Alpha (Grid): 300.0000\n",
            "Ridge - Best Log RMSE (Grid CV): 0.1492\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "ridge = Ridge(random_state=42)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# We focus the search around the best alpha of 215.4435\n",
        "param_grid_ridge_fine = {\n",
        "    # Creating 10 steps for alpha between 100 and 300\n",
        "    'alpha': np.linspace(100, 300, 10)\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    estimator=ridge,\n",
        "    param_grid=param_grid_ridge_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "# X_train and y_train_log are the scaled features and log target\n",
        "ridge_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_ridge = ridge_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-ridge_grid_search.best_score_)\n",
        "print('\\n--- Ridge Fine-Tuning Complete ---')\n",
        "print(f\"Ridge - Best Alpha (Grid): {ridge_grid_search.best_params_['alpha']:.4f}\")\n",
        "print(f\"Ridge - Best Log RMSE (Grid CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acee4653",
      "metadata": {
        "id": "acee4653"
      },
      "source": [
        "LASSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ab77e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ab77e0",
        "outputId": "0601096d-b84f-45b6-c254-38726f4045d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "--- Lasso Fine-Tuning Complete ---\n",
            "Lasso - Best Alpha (Grid): 0.003000\n",
            "Lasso - Best Log RMSE (Grid CV): 0.1563\n"
          ]
        }
      ],
      "source": [
        "# Define the model and set max_iter high for convergence\n",
        "lasso = Lasso(random_state=42, max_iter=5000)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# Focusing the search around the best alpha of 0.002069\n",
        "param_grid_lasso_fine = {\n",
        "    # Creating 10 steps for alpha between 0.001 and 0.003\n",
        "    'alpha': np.linspace(0.001, 0.003, 10)\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "lasso_grid_search = GridSearchCV(\n",
        "    estimator=lasso,\n",
        "    param_grid=param_grid_lasso_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "# X_train and y_train_log are the scaled features and log target\n",
        "lasso_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_lasso = lasso_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-lasso_grid_search.best_score_)\n",
        "print('\\n--- Lasso Fine-Tuning Complete ---')\n",
        "print(f\"Lasso - Best Alpha (Grid): {lasso_grid_search.best_params_['alpha']:.6f}\")\n",
        "print(f\"Lasso - Best Log RMSE (Grid CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92728c5",
      "metadata": {
        "id": "f92728c5"
      },
      "source": [
        "Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6132e08e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6132e08e",
        "outputId": "069d57ca-561f-4af7-f71e-3290aa719a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "--- ElasticNet Fine-Tuning Complete ---\n",
            "ElasticNet - Best Parameters (Grid): {'alpha': np.float64(0.04), 'l1_ratio': 0.15}\n",
            "ElasticNet - Best Log RMSE (Grid CV): 0.1509 \n"
          ]
        }
      ],
      "source": [
        "# Initialize the model with max_iter for convergence\n",
        "elastic_net = ElasticNet(random_state=42, max_iter=5000)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# We focus the search around the best alpha (0.0215) and keep l1_ratio close to 0.1\n",
        "param_grid_elastic_fine = {\n",
        "    # Narrow range for alpha around 0.0215\n",
        "    'alpha': np.linspace(0.01, 0.04, 10),\n",
        "    # Narrow range for l1_ratio around 0.1\n",
        "    'l1_ratio': [0.05, 0.1, 0.15]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "elastic_grid_search = GridSearchCV(\n",
        "    estimator=elastic_net,\n",
        "    param_grid=param_grid_elastic_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "elastic_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_elastic = elastic_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-elastic_grid_search.best_score_)\n",
        "print('\\n--- ElasticNet Fine-Tuning Complete ---')\n",
        "print(f'ElasticNet - Best Parameters (Grid): {elastic_grid_search.best_params_}')\n",
        "print(f'ElasticNet - Best Log RMSE (Grid CV): {best_score:.4f} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a1471a",
      "metadata": {
        "id": "27a1471a"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee19630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ee19630",
        "outputId": "7c5fa08b-1003-4438-c726-69d6a1f1b634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "\n",
            "--- Random Forest Fine-Tuning Complete ---\n",
            "Random Forest - Best Parameters (Grid): {'max_depth': 14, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
            "Random Forest - Best Log RMSE (Grid CV): 0.1378\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "# Use a reasonable base based on what RandomizedSearch may have suggested\n",
        "random_forest = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# These values should be based on the best results from your prior RandomizedSearchCV\n",
        "param_grid_rf_fine = {\n",
        "    # Check around the best n_estimators (e.g., 250, 300, 350)\n",
        "    'n_estimators': [250, 300, 350],\n",
        "    # Check slightly above and below the best max_depth\n",
        "    'max_depth': [12, 14, 16],\n",
        "    # Fine-tune min_samples_leaf\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=random_forest,\n",
        "    param_grid=param_grid_rf_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "rf_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-rf_grid_search.best_score_)\n",
        "print('\\n--- Random Forest Fine-Tuning Complete ---')\n",
        "print(f'Random Forest - Best Parameters (Grid): {rf_grid_search.best_params_}')\n",
        "print(f'Random Forest - Best Log RMSE (Grid CV): {best_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c82057",
      "metadata": {
        "id": "04c82057"
      },
      "source": [
        "XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d3967c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30d3967c",
        "outputId": "568c0e86-1d2b-4787-d90c-bafdee518567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "\n",
            "--- XGBoost Fine-Tuning Complete ---\n",
            "XGBoost - Best Parameters (Grid): {'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 700}\n",
            "XGBoost - Best Log RMSE (Grid CV): 0.1265\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model with good default parameters\n",
        "# Use 'gbtree' booster which is standard tree-based model\n",
        "xgb_model = XGBRegressor(random_state=42, booster='gbtree', n_jobs=-1)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# These values should be based on the best results from your prior RandomizedSearchCV\n",
        "param_grid_xgb_fine = {\n",
        "    # Check around the best learning rate\n",
        "    'learning_rate': [0.03, 0.05, 0.07],\n",
        "    # Check around the best tree complexity\n",
        "    'max_depth': [3, 4, 5],\n",
        "    # Check around the best number of trees\n",
        "    'n_estimators': [500, 600, 700]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "xgb_grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid_xgb_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "xgb_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_xgb = xgb_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-xgb_grid_search.best_score_)\n",
        "print('\\n--- XGBoost Fine-Tuning Complete ---')\n",
        "print(f'XGBoost - Best Parameters (Grid): {xgb_grid_search.best_params_}')\n",
        "print(f'XGBoost - Best Log RMSE (Grid CV): {best_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7AhvHAvXue8w",
      "metadata": {
        "id": "7AhvHAvXue8w"
      },
      "source": [
        "Lasso Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zbhl9WsVuSZE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbhl9WsVuSZE",
        "outputId": "823054e8-c9ab-4b86-e0e5-d4fae23390c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned Lasso Model...\n",
            "\n",
            "--- Submission File Created ---\n",
            "File Name: submission_lasso_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  148929.851288\n",
            "1  1106  316850.075368\n",
            "2   414  106207.679685\n",
            "3   523  161429.847853\n",
            "4  1037  294558.472037\n"
          ]
        }
      ],
      "source": [
        "# --- 10. Final Prediction and Submission (Corrected) ---\n",
        "print('\\nStarting Final Prediction using Tuned Lasso Model...')\n",
        "from sklearn.linear_model import Lasso\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD THE IDs from the original RAW test file\n",
        "# This file is guaranteed to have the original 'Id' column.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features without 'Id'\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best Lasso model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_lasso' was defined and trained in a previous cell.\n",
        "final_lasso_model = best_lasso\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_lasso_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_lasso_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created ---\")\n",
        "print(\"File Name: submission_lasso_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s0TKBNfEuxQ8",
      "metadata": {
        "id": "s0TKBNfEuxQ8"
      },
      "source": [
        "Linear Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_uslj9Jwu5Dg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uslj9Jwu5Dg",
        "outputId": "2cb90a47-845b-4760-f994-0f5c0747e622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Final Prediction using OLS Linear Regression Model...\n",
            "\n",
            "--- OLS Submission File Created ---\n",
            "File Name: submission_ols_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  152056.670265\n",
            "1  1106  348485.481933\n",
            "2   414  100053.799726\n",
            "3   523  168251.803878\n",
            "4  1037  300276.724470\n"
          ]
        }
      ],
      "source": [
        "# --- 11. Final Prediction and Submission (OLS) ---\n",
        "print('\\nStarting Final Prediction using OLS Linear Regression Model...')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best OLS model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_ols' was defined and trained in a previous cell.\n",
        "final_ols_model = best_ols\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_ols_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_ols_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- OLS Submission File Created ---\")\n",
        "print(\"File Name: submission_ols_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N9jInIF0xEU6",
      "metadata": {
        "id": "N9jInIF0xEU6"
      },
      "source": [
        "xgBoost Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9qx6PdmrxGoc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qx6PdmrxGoc",
        "outputId": "e31b1e97-ea77-4bde-f590-c58693546aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned XGBoost Model...\n",
            "\n",
            "--- XGBoost Submission File Created ---\n",
            "File Name: submission_xgb_final.csv\n",
            "Submission Head:\n",
            "     Id    HotelValue\n",
            "0   893  145901.46875\n",
            "1  1106  344845.43750\n",
            "2   414  106586.06250\n",
            "3   523  160984.71875\n",
            "4  1037  326256.18750\n"
          ]
        }
      ],
      "source": [
        "# --- 14. Final Prediction and Submission (XGBoost) ---\n",
        "print('\\nStarting Final Prediction using Tuned XGBoost Model...')\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best XGBoost model found by GridSearchCV/RandomizedSearchCV\n",
        "# NOTE: This assumes the variable 'best_xgb' was defined and trained in a previous cell.\n",
        "final_xgb_model = best_xgb\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_xgb_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_xgb_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- XGBoost Submission File Created ---\")\n",
        "print(\"File Name: submission_xgb_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-DCo8nGFyEUL",
      "metadata": {
        "id": "-DCo8nGFyEUL"
      },
      "source": [
        "Elastic net Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kgENdxbFyJVR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgENdxbFyJVR",
        "outputId": "50a880cf-37ba-4d79-97e1-4b7e76d88cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned ElasticNet Model...\n",
            "\n",
            "--- ElasticNet Submission File Created ---\n",
            "File Name: submission_elastic_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  147852.188015\n",
            "1  1106  312108.706816\n",
            "2   414  109781.286913\n",
            "3   523  154914.193929\n",
            "4  1037  289483.130153\n"
          ]
        }
      ],
      "source": [
        "# --- 15. Final Prediction and Submission (ElasticNet) ---\n",
        "print('\\nStarting Final Prediction using Tuned ElasticNet Model...')\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best ElasticNet model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_elastic' was defined and trained in a previous cell.\n",
        "final_elastic_model = best_elastic\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_elastic_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_elastic_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- ElasticNet Submission File Created ---\")\n",
        "print(\"File Name: submission_elastic_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
