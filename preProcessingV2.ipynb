{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c98795be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split # Used if you were splitting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52952e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1200, 81)\n",
      "Testing Data Shape: (260, 80)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Training Data Shape:\", df_train.shape)\n",
    "print(\"Testing Data Shape:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b94797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 'Id' columns for submission\n",
    "test_ID = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "193122d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Id' column from the dataframes\n",
    "df_train.drop(\"Id\", axis=1, inplace=True)\n",
    "df_test.drop(\"Id\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dfa3079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PropertyClass         0\n",
      "ZoningCategory        0\n",
      "RoadAccessLength    223\n",
      "LandArea              0\n",
      "RoadType              0\n",
      "                   ... \n",
      "MonthSold             0\n",
      "YearSold              0\n",
      "DealType              0\n",
      "DealCondition         0\n",
      "HotelValue            0\n",
      "Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_counts = df_train.isna().sum().astype(np.int64)\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d630b10",
   "metadata": {},
   "source": [
    "Clearing the columns with many NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06a68566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoolQuality        1194\n",
      "ExtraFacility      1154\n",
      "ServiceLaneType    1125\n",
      "BoundaryFence       963\n",
      "LoungeQuality       560\n",
      "FacadeType          702\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_counts = (\n",
    "    df_train[['PoolQuality', 'ExtraFacility', 'ServiceLaneType', 'BoundaryFence','LoungeQuality','FacadeType']]\n",
    "    .isna()\n",
    "    .sum()\n",
    "    .astype(np.int64)\n",
    ")\n",
    "\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "761175fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoolQuality        259\n",
      "ExtraFacility      252\n",
      "ServiceLaneType    244\n",
      "BoundaryFence      216\n",
      "LoungeQuality      130\n",
      "FacadeType         170\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_counts = (\n",
    "    df_test[['PoolQuality', 'ExtraFacility', 'ServiceLaneType', 'BoundaryFence','LoungeQuality','FacadeType']]\n",
    "    .isna()\n",
    "    .sum()\n",
    "    .astype(np.int64)\n",
    ")\n",
    "\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e043dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_to_drop = [\n",
    "    'PoolQuality', 'ExtraFacility', 'ServiceLaneType', \n",
    "    'BoundaryFence', 'FacadeType','LoungeQuality'\n",
    "]\n",
    "df_train = df_train.drop(columns=cols_to_drop)\n",
    "df_test = df_test.drop(columns=cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7933a35",
   "metadata": {},
   "source": [
    "For some columns very less amount of data is missing so its better to remove those rows as it will confuse our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c7ad26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectricalSystem    1\n",
      "dtype: int64\n",
      "ElectricalSystem    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_train[['ElectricalSystem']].isna().sum().astype(np.int64))\n",
    "print(df_test[['ElectricalSystem']].isna().sum().astype(np.int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e90818c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset=['ElectricalSystem'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265e053",
   "metadata": {},
   "source": [
    "Impute NaN values with 'None' for features where missing means absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02739d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basement-related columns\n",
    "basement_cols = [\n",
    "    'BasementHeight', 'BasementCondition', 'BasementExposure', \n",
    "    'BasementFacilityType1', 'BasementFacilityType2'\n",
    "]\n",
    "df_train[basement_cols] = df_train[basement_cols].fillna('None')\n",
    "df_test[basement_cols] = df_test[basement_cols].fillna('None')\n",
    "\n",
    "# Garage/Parking related columns (excluding ParkingConstructionYear)\n",
    "parking_cat_cols = [\n",
    "    'ParkingType', 'ParkingFinish', 'ParkingQuality', \n",
    "    'ParkingCondition'\n",
    "]\n",
    "df_train[parking_cat_cols] = df_train[parking_cat_cols].fillna('None')\n",
    "df_test[parking_cat_cols] = df_test[parking_cat_cols].fillna('None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea81b1",
   "metadata": {},
   "source": [
    "Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "715e337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.duplicated().sum())\n",
    "print(df_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235396d",
   "metadata": {},
   "source": [
    "Possible incosistencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bc3ba",
   "metadata": {},
   "source": [
    "\n",
    "RenovationYear < ConstructionYear\n",
    "\n",
    "YearSold < ConstructionYear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ec4e61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 1199\n",
      "Cleaned rows: 1199\n",
      "Rows removed: 0\n",
      "Original rows: 260\n",
      "Cleaned rows: 260\n",
      "Rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned1 = df_train[\n",
    "    (df_train['RenovationYear'] >= df_train['ConstructionYear']) &\n",
    "    (df_train['YearSold'] >= df_train['ConstructionYear'])\n",
    "].copy()\n",
    "\n",
    "print(\"Original rows:\", len(df_train))\n",
    "print(\"Cleaned rows:\", len(df_cleaned1))\n",
    "print(\"Rows removed:\", len(df_train) - len(df_cleaned1))\n",
    "\n",
    "df_train = df_cleaned1\n",
    "\n",
    "\n",
    "df_cleaned2 = df_test[\n",
    "    (df_test['RenovationYear'] >= df_test['ConstructionYear']) &\n",
    "    (df_test['YearSold'] >= df_test['ConstructionYear'])\n",
    "].copy()\n",
    "\n",
    "print(\"Original rows:\", len(df_test))\n",
    "print(\"Cleaned rows:\", len(df_cleaned2))\n",
    "print(\"Rows removed:\", len(df_test) - len(df_cleaned2))\n",
    "\n",
    "df_test = df_cleaned2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11305e",
   "metadata": {},
   "source": [
    "Creating temporal features and removing original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15174461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train['TotalOutdoorArea'] = (df_train['TerraceArea'] + df_train['OpenVerandaArea'] + df_train['EnclosedVerandaArea'] + df_train['ScreenPorchArea']).fillna(0)\n",
    "df_train['TotalSF'] = (df_train['GroundFloorArea'] + df_train['UpperFloorArea'] + df_train['ParkingArea'] + df_train['TotalOutdoorArea']).fillna(0)\n",
    "\n",
    "df_train['TotalBaths'] = (df_train['FullBaths'] + 0.5 * df_train['HalfBaths'] +\n",
    "                    df_train['BasementFullBaths'] + 0.5 * df_train['BasementHalfBaths']).fillna(0)\n",
    "\n",
    "df_train['OverallScore'] = (df_train['OverallQuality'] + df_train['OverallCondition']) / 2.0 # Assumes these columns were NOT dropped\n",
    "\n",
    "# --- 2. Temporal Features ---\n",
    "df_train['Age'] = df_train['YearSold'] - df_train['ConstructionYear']\n",
    "df_train['YearsSinceRemodel'] = df_train['YearSold'] - df_train['RenovationYear']\n",
    "df_train['YearsSinceRemodel'] = np.where(df_train['YearsSinceRemodel'] < 0, 0, df_train['YearsSinceRemodel'])\n",
    "df_train.loc[df_train['RenovationYear'] == df_train['ConstructionYear'], 'YearsSinceRemodel'] = df_train['Age']\n",
    "\n",
    "# --- 3. Interaction Feature (Example) ---\n",
    "df_train['Qual_x_GroundSF'] = df_train['OverallQuality'] * df_train['GroundFloorArea'] # Assumes these columns were NOT dropped\n",
    "\n",
    "# --- 4. Feature Reduction/Drop ---\n",
    "drop_cols = ['GroundFloorArea', 'UpperFloorArea', \n",
    "                'ConstructionYear', 'RenovationYear', \n",
    "                'FullBaths', 'HalfBaths','ParkingArea',\n",
    "                'BasementFullBaths', 'BasementHalfBaths', 'BasementFacilitySF1', 'BasementFacilitySF2', \n",
    "                'TerraceArea', 'OpenVerandaArea','EnclosedVerandaArea', 'ScreenPorchArea','OverallQuality', 'OverallCondition', 'SeasonalPorchArea']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f8052a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test['TotalOutdoorArea'] = (df_test['TerraceArea'] + df_test['OpenVerandaArea'] + df_test['EnclosedVerandaArea'] + df_test['ScreenPorchArea']).fillna(0)\n",
    "df_test['TotalSF'] = (df_test['GroundFloorArea'] + df_test['UpperFloorArea'] + df_test['ParkingArea'] + df_test['TotalOutdoorArea']).fillna(0)\n",
    "\n",
    "df_test['TotalBaths'] = (df_test['FullBaths'] + 0.5 * df_test['HalfBaths'] +\n",
    "                    df_test['BasementFullBaths'] + 0.5 * df_test['BasementHalfBaths']).fillna(0)\n",
    "\n",
    "df_test['OverallScore'] = (df_test['OverallQuality'] + df_test['OverallCondition']) / 2.0 # Assumes these columns were NOT dropped\n",
    "\n",
    "# --- 2. Temporal Features ---\n",
    "df_test['Age'] = df_test['YearSold'] - df_test['ConstructionYear']\n",
    "df_test['YearsSinceRemodel'] = df_test['YearSold'] - df_test['RenovationYear']\n",
    "df_test['YearsSinceRemodel'] = np.where(df_test['YearsSinceRemodel'] < 0, 0, df_test['YearsSinceRemodel'])\n",
    "df_test.loc[df_test['RenovationYear'] == df_test['ConstructionYear'], 'YearsSinceRemodel'] = df_test['Age']\n",
    "\n",
    "# --- 3. Interaction Feature (Example) ---\n",
    "df_test['Qual_x_GroundSF'] = df_test['OverallQuality'] * df_test['GroundFloorArea'] # Assumes these columns were NOT dropped\n",
    "\n",
    "# --- 4. Feature Reduction/Drop ---\n",
    "drop_cols = ['GroundFloorArea', 'UpperFloorArea', \n",
    "                'ConstructionYear', 'RenovationYear', \n",
    "                'FullBaths', 'HalfBaths','ParkingArea',\n",
    "                'BasementFullBaths', 'BasementHalfBaths', 'BasementFacilitySF1', 'BasementFacilitySF2', \n",
    "                'TerraceArea', 'OpenVerandaArea','EnclosedVerandaArea', 'ScreenPorchArea','OverallQuality', 'OverallCondition', 'SeasonalPorchArea']\n",
    "df_train.drop(columns=drop_cols, inplace=True)\n",
    "df_test.drop(columns=drop_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffce6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26708/1916592955.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['FacadeArea'].fillna(median_facade_area, inplace=True)\n",
      "/tmp/ipykernel_26708/1916592955.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['RoadAccessLength'].fillna(median_road_access, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "median_facade_area = df_train['FacadeArea'].median()\n",
    "df_train['FacadeArea'].fillna(median_facade_area, inplace=True)\n",
    "\n",
    "median_road_access = df_train['RoadAccessLength'].median()\n",
    "df_train['RoadAccessLength'].fillna(median_road_access, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9eba9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26708/2669533664.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test['FacadeArea'].fillna(median_facade_area, inplace=True)\n",
      "/tmp/ipykernel_26708/2669533664.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test['RoadAccessLength'].fillna(median_road_access, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "median_facade_area = df_test['FacadeArea'].median()\n",
    "df_test['FacadeArea'].fillna(median_facade_area, inplace=True)\n",
    "\n",
    "median_road_access = df_test['RoadAccessLength'].median()\n",
    "df_test['RoadAccessLength'].fillna(median_road_access, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bee4c",
   "metadata": {},
   "source": [
    "Check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a80244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = ['TotalSF', 'LandArea']\n",
    "target_col = 'HotelValue'\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i, col in enumerate(outlier_features):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    # Generate scatter plot\n",
    "    sns.scatterplot(x=df_train[col], y=df_train[target_col])\n",
    "    plt.title(f'{col} vs. {target_col}', fontsize=12)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(target_col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outlier_scatterplots_V2.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c9246",
   "metadata": {},
   "source": [
    "Removing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37db028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR-based removal identified 71 total rows to drop.\n",
      "\n",
      "Total unique rows dropped from all checks: 71\n",
      "Remaining training rows: 1128\n"
     ]
    }
   ],
   "source": [
    "# 1. Define columns for IQR analysis\n",
    "iqr_cols = ['TotalSF', 'LandArea'] \n",
    "\n",
    "# Initialize an index set for IQR outliers to drop\n",
    "outlier_iqr_indices = pd.Index([])\n",
    "\n",
    "for col in iqr_cols:\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = df_train[col].quantile(0.25)\n",
    "    Q3 = df_train[col].quantile(0.75)\n",
    "    \n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define the outlier bounds (Q1 - 1.5*IQR and Q3 + 1.5*IQR)\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Find indices outside these IQR-based bounds\n",
    "    out_of_range_indices = df_train[(df_train[col] < lower_bound) | (df_train[col] > upper_bound)].index\n",
    "    \n",
    "    # Add these new outlier indices to the overall set\n",
    "    outlier_iqr_indices = outlier_iqr_indices.union(out_of_range_indices)\n",
    "\n",
    "print(f\"IQR-based removal identified {len(outlier_iqr_indices)} total rows to drop.\")\n",
    "\n",
    "\n",
    "# --- 5. Consolidate ALL Outliers and Execute Final Drop ---\n",
    "\n",
    "# Outliers previously identified by manual checks (assuming these lines are run earlier)\n",
    "outlier_tsf_indices = df_train[(df_train['TotalSF'] > 6000) & (df_train['HotelValue'] < 12.5)].index\n",
    "outlier_land_indices = df_train[(df_train['LandArea'] > 50000) & (df_train['HotelValue'] < 13)].index\n",
    "\n",
    "# Combine ALL outliers (manual checks and IQR checks)\n",
    "outliers_to_drop = outlier_tsf_indices.union(outlier_land_indices).union(outlier_iqr_indices)\n",
    "\n",
    "# Execute the drop operation\n",
    "df_train.drop(outliers_to_drop, inplace=True)\n",
    "\n",
    "print(f\"\\nTotal unique rows dropped from all checks: {len(outliers_to_drop)}\")\n",
    "print(f\"Remaining training rows: {df_train.shape[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4919fa18",
   "metadata": {},
   "source": [
    "Pre Processed CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78d4af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('preprocesssed_train_V2.csv',index=False)\n",
    "df_test.to_csv('preprocesssed_test_V2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "322d68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your currently saved processed data\n",
    "X_train = pd.read_csv('preprocesssed_train_V2.csv')\n",
    "X_test = pd.read_csv('preprocesssed_test_V2.csv')\n",
    "\n",
    "# --- 1. Separate Target and Features ---\n",
    "# Assume 'HotelValue_Log' is the log-transformed target you created\n",
    "y_train = X_train['HotelValue']\n",
    "X_train.drop(columns=['HotelValue'], inplace=True, errors='ignore')\n",
    "X_test.drop(columns=['HotelValue'], inplace=True, errors='ignore') # Test set usually has no target\n",
    "\n",
    "# --- 2. Categorical Encoding (One-Hot) ---\n",
    "# Identify all remaining text columns\n",
    "nominal_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Combine for unified One-Hot Encoding (Crucial for consistent columns)\n",
    "combined_df = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "combined_encoded = pd.get_dummies(combined_df, columns=nominal_cols, drop_first=True)\n",
    "\n",
    "# Separate back into encoded train and test sets\n",
    "X_train_encoded = combined_encoded.iloc[:len(X_train)]\n",
    "X_test_encoded = combined_encoded.iloc[len(X_train):]\n",
    "\n",
    "# --- 3. Feature Scaling (Fit on Train, Transform on Test) ---\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FIT and TRANSFORM the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "# ONLY TRANSFORM the test data using the parameters learned from the training data\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_encoded.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_encoded.columns)\n",
    "\n",
    "# Reattach the target to the training data\n",
    "X_train_scaled_df['HotelValue'] = y_train.values \n",
    "\n",
    "# --- 4. Final Save ---\n",
    "X_train_scaled_df.to_csv('final_processed_train_V2.csv', index=False)\n",
    "X_test_scaled_df.to_csv('final_processed_test_V2.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpro_env (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
