{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTDD47Z7Ie8M",
        "outputId": "ad8f25f7-9a5a-4445-f411-51b8ada3085a"
      },
      "id": "hTDD47Z7Ie8M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6fae0c",
      "metadata": {
        "id": "ba6fae0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9ab8aa",
      "metadata": {
        "id": "ad9ab8aa"
      },
      "source": [
        "Helper function to convert Log RMSE back to RMSE\n",
        "\n",
        "Reverse log transform (np.expm1 is the inverse of np.log1p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a3625a",
      "metadata": {
        "id": "48a3625a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rmse_from_log_rmse(y_true_log, y_pred_log):\n",
        "\n",
        "    y_true = np.expm1(y_true_log)\n",
        "    y_pred = np.expm1(y_pred_log)\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ddf679c",
      "metadata": {
        "id": "5ddf679c"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660f8f5d",
      "metadata": {
        "id": "660f8f5d"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('final_processed_train.csv')\n",
        "X_test = pd.read_csv('final_processed_test.csv')\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "y_train_log = X_train['HotelValue_Log']\n",
        "X_train.drop(columns=['HotelValue_Log'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb441efa",
      "metadata": {
        "id": "bb441efa"
      },
      "source": [
        "5 Fold cross validation is standard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e98ef68",
      "metadata": {
        "id": "8e98ef68"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4030022a",
      "metadata": {
        "id": "4030022a"
      },
      "source": [
        "Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86474bcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86474bcb",
        "outputId": "af3337ae-d071-4341-ff4e-d6f8bd34d5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "--- OLS Baseline Complete ---\n",
            "OLS - Cross-Validation Log RMSE: 0.2032\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the model (OLS has no hyperparameters to tune)\n",
        "ols_model = LinearRegression(n_jobs=-1)\n",
        "\n",
        "# The parameter grid is empty since OLS has no tuning parameters.\n",
        "# GridSearchCV will simply use the model as-is across all CV folds.\n",
        "param_grid_ols = {}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "ols_grid_search = GridSearchCV(\n",
        "    estimator=ols_model,\n",
        "    param_grid=param_grid_ols,  # Empty grid just runs the model once per CV fold\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the OLS baseline test\n",
        "ols_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_ols = ols_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-ols_grid_search.best_score_)\n",
        "print('\\n--- OLS Baseline Complete ---')\n",
        "print(f\"OLS - Cross-Validation Log RMSE: {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75021708",
      "metadata": {
        "id": "75021708"
      },
      "source": [
        "Ridge Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85bfde99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85bfde99",
        "outputId": "48511f06-58f9-45ff-8713-4abfacb1ea00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "--- Ridge Fine-Tuning Complete ---\n",
            "Ridge - Best Alpha (Grid): 300.0000\n",
            "Ridge - Best Log RMSE (Grid CV): 0.1492\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "ridge = Ridge(random_state=42)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# We focus the search around the best alpha of 215.4435\n",
        "param_grid_ridge_fine = {\n",
        "    # Creating 10 steps for alpha between 100 and 300\n",
        "    'alpha': np.linspace(100, 300, 10)\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    estimator=ridge,\n",
        "    param_grid=param_grid_ridge_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "# X_train and y_train_log are the scaled features and log target\n",
        "ridge_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_ridge = ridge_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-ridge_grid_search.best_score_)\n",
        "print('\\n--- Ridge Fine-Tuning Complete ---')\n",
        "print(f\"Ridge - Best Alpha (Grid): {ridge_grid_search.best_params_['alpha']:.4f}\")\n",
        "print(f\"Ridge - Best Log RMSE (Grid CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acee4653",
      "metadata": {
        "id": "acee4653"
      },
      "source": [
        "LASSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ab77e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ab77e0",
        "outputId": "0601096d-b84f-45b6-c254-38726f4045d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "\n",
            "--- Lasso Fine-Tuning Complete ---\n",
            "Lasso - Best Alpha (Grid): 0.003000\n",
            "Lasso - Best Log RMSE (Grid CV): 0.1563\n"
          ]
        }
      ],
      "source": [
        "# Define the model and set max_iter high for convergence\n",
        "lasso = Lasso(random_state=42, max_iter=5000)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# Focusing the search around the best alpha of 0.002069\n",
        "param_grid_lasso_fine = {\n",
        "    # Creating 10 steps for alpha between 0.001 and 0.003\n",
        "    'alpha': np.linspace(0.001, 0.003, 10)\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "lasso_grid_search = GridSearchCV(\n",
        "    estimator=lasso,\n",
        "    param_grid=param_grid_lasso_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "# X_train and y_train_log are the scaled features and log target\n",
        "lasso_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_lasso = lasso_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-lasso_grid_search.best_score_)\n",
        "print('\\n--- Lasso Fine-Tuning Complete ---')\n",
        "print(f\"Lasso - Best Alpha (Grid): {lasso_grid_search.best_params_['alpha']:.6f}\")\n",
        "print(f\"Lasso - Best Log RMSE (Grid CV): {best_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92728c5",
      "metadata": {
        "id": "f92728c5"
      },
      "source": [
        "Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6132e08e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6132e08e",
        "outputId": "069d57ca-561f-4af7-f71e-3290aa719a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "--- ElasticNet Fine-Tuning Complete ---\n",
            "ElasticNet - Best Parameters (Grid): {'alpha': np.float64(0.04), 'l1_ratio': 0.15}\n",
            "ElasticNet - Best Log RMSE (Grid CV): 0.1509 \n"
          ]
        }
      ],
      "source": [
        "# Initialize the model with max_iter for convergence\n",
        "elastic_net = ElasticNet(random_state=42, max_iter=5000)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# We focus the search around the best alpha (0.0215) and keep l1_ratio close to 0.1\n",
        "param_grid_elastic_fine = {\n",
        "    # Narrow range for alpha around 0.0215\n",
        "    'alpha': np.linspace(0.01, 0.04, 10),\n",
        "    # Narrow range for l1_ratio around 0.1\n",
        "    'l1_ratio': [0.05, 0.1, 0.15]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "elastic_grid_search = GridSearchCV(\n",
        "    estimator=elastic_net,\n",
        "    param_grid=param_grid_elastic_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "elastic_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_elastic = elastic_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-elastic_grid_search.best_score_)\n",
        "print('\\n--- ElasticNet Fine-Tuning Complete ---')\n",
        "print(f'ElasticNet - Best Parameters (Grid): {elastic_grid_search.best_params_}')\n",
        "print(f'ElasticNet - Best Log RMSE (Grid CV): {best_score:.4f} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a1471a",
      "metadata": {
        "id": "27a1471a"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee19630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ee19630",
        "outputId": "7c5fa08b-1003-4438-c726-69d6a1f1b634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "\n",
            "--- Random Forest Fine-Tuning Complete ---\n",
            "Random Forest - Best Parameters (Grid): {'max_depth': 14, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
            "Random Forest - Best Log RMSE (Grid CV): 0.1378\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "# Use a reasonable base based on what RandomizedSearch may have suggested\n",
        "random_forest = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# These values should be based on the best results from your prior RandomizedSearchCV\n",
        "param_grid_rf_fine = {\n",
        "    # Check around the best n_estimators (e.g., 250, 300, 350)\n",
        "    'n_estimators': [250, 300, 350],\n",
        "    # Check slightly above and below the best max_depth\n",
        "    'max_depth': [12, 14, 16],\n",
        "    # Fine-tune min_samples_leaf\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=random_forest,\n",
        "    param_grid=param_grid_rf_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "rf_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-rf_grid_search.best_score_)\n",
        "print('\\n--- Random Forest Fine-Tuning Complete ---')\n",
        "print(f'Random Forest - Best Parameters (Grid): {rf_grid_search.best_params_}')\n",
        "print(f'Random Forest - Best Log RMSE (Grid CV): {best_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c82057",
      "metadata": {
        "id": "04c82057"
      },
      "source": [
        "XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d3967c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30d3967c",
        "outputId": "568c0e86-1d2b-4787-d90c-bafdee518567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "\n",
            "--- XGBoost Fine-Tuning Complete ---\n",
            "XGBoost - Best Parameters (Grid): {'learning_rate': 0.07, 'max_depth': 5, 'n_estimators': 700}\n",
            "XGBoost - Best Log RMSE (Grid CV): 0.1265\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model with good default parameters\n",
        "# Use 'gbtree' booster which is standard tree-based model\n",
        "xgb_model = XGBRegressor(random_state=42, booster='gbtree', n_jobs=-1)\n",
        "\n",
        "# Define a narrow, targeted parameter grid for GridSearchCV\n",
        "# These values should be based on the best results from your prior RandomizedSearchCV\n",
        "param_grid_xgb_fine = {\n",
        "    # Check around the best learning rate\n",
        "    'learning_rate': [0.03, 0.05, 0.07],\n",
        "    # Check around the best tree complexity\n",
        "    'max_depth': [3, 4, 5],\n",
        "    # Check around the best number of trees\n",
        "    'n_estimators': [500, 600, 700]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "xgb_grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid_xgb_fine,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Run the grid search\n",
        "xgb_grid_search.fit(X_train, y_train_log)\n",
        "\n",
        "# Output Results\n",
        "best_xgb = xgb_grid_search.best_estimator_\n",
        "# Convert 'neg_mean_squared_error' score back to positive Log RMSE\n",
        "best_score = np.sqrt(-xgb_grid_search.best_score_)\n",
        "print('\\n--- XGBoost Fine-Tuning Complete ---')\n",
        "print(f'XGBoost - Best Parameters (Grid): {xgb_grid_search.best_params_}')\n",
        "print(f'XGBoost - Best Log RMSE (Grid CV): {best_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso Submission"
      ],
      "metadata": {
        "id": "7AhvHAvXue8w"
      },
      "id": "7AhvHAvXue8w"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10. Final Prediction and Submission (Corrected) ---\n",
        "print('\\nStarting Final Prediction using Tuned Lasso Model...')\n",
        "from sklearn.linear_model import Lasso\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD THE IDs from the original RAW test file\n",
        "# This file is guaranteed to have the original 'Id' column.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features without 'Id'\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best Lasso model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_lasso' was defined and trained in a previous cell.\n",
        "final_lasso_model = best_lasso\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_lasso_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_lasso_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created ---\")\n",
        "print(\"File Name: submission_lasso_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbhl9WsVuSZE",
        "outputId": "823054e8-c9ab-4b86-e0e5-d4fae23390c6"
      },
      "id": "Zbhl9WsVuSZE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned Lasso Model...\n",
            "\n",
            "--- Submission File Created ---\n",
            "File Name: submission_lasso_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  148929.851288\n",
            "1  1106  316850.075368\n",
            "2   414  106207.679685\n",
            "3   523  161429.847853\n",
            "4  1037  294558.472037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Submission"
      ],
      "metadata": {
        "id": "s0TKBNfEuxQ8"
      },
      "id": "s0TKBNfEuxQ8"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11. Final Prediction and Submission (OLS) ---\n",
        "print('\\nStarting Final Prediction using OLS Linear Regression Model...')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best OLS model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_ols' was defined and trained in a previous cell.\n",
        "final_ols_model = best_ols\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_ols_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_ols_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- OLS Submission File Created ---\")\n",
        "print(\"File Name: submission_ols_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uslj9Jwu5Dg",
        "outputId": "2cb90a47-845b-4760-f994-0f5c0747e622"
      },
      "id": "_uslj9Jwu5Dg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using OLS Linear Regression Model...\n",
            "\n",
            "--- OLS Submission File Created ---\n",
            "File Name: submission_ols_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  152056.670265\n",
            "1  1106  348485.481933\n",
            "2   414  100053.799726\n",
            "3   523  168251.803878\n",
            "4  1037  300276.724470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "xgBoost Submission"
      ],
      "metadata": {
        "id": "N9jInIF0xEU6"
      },
      "id": "N9jInIF0xEU6"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 14. Final Prediction and Submission (XGBoost) ---\n",
        "print('\\nStarting Final Prediction using Tuned XGBoost Model...')\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best XGBoost model found by GridSearchCV/RandomizedSearchCV\n",
        "# NOTE: This assumes the variable 'best_xgb' was defined and trained in a previous cell.\n",
        "final_xgb_model = best_xgb\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_xgb_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_xgb_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- XGBoost Submission File Created ---\")\n",
        "print(\"File Name: submission_xgb_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qx6PdmrxGoc",
        "outputId": "e31b1e97-ea77-4bde-f590-c58693546aa9"
      },
      "id": "9qx6PdmrxGoc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned XGBoost Model...\n",
            "\n",
            "--- XGBoost Submission File Created ---\n",
            "File Name: submission_xgb_final.csv\n",
            "Submission Head:\n",
            "     Id    HotelValue\n",
            "0   893  145901.46875\n",
            "1  1106  344845.43750\n",
            "2   414  106586.06250\n",
            "3   523  160984.71875\n",
            "4  1037  326256.18750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic net Submission"
      ],
      "metadata": {
        "id": "-DCo8nGFyEUL"
      },
      "id": "-DCo8nGFyEUL"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 15. Final Prediction and Submission (ElasticNet) ---\n",
        "print('\\nStarting Final Prediction using Tuned ElasticNet Model...')\n",
        "# 1. LOAD the IDs from the original RAW test file\n",
        "# This is crucial as the processed file drops 'Id'.\n",
        "test_ids_df = pd.read_csv('test.csv')\n",
        "test_ids = test_ids_df['Id'] # Extract the Id series\n",
        "\n",
        "# 2. LOAD the PROCESSED features for prediction\n",
        "# This file contains all the scaled and encoded features\n",
        "X_test_processed = pd.read_csv('final_processed_test.csv')\n",
        "X_test_processed.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Use the best ElasticNet model found by GridSearchCV\n",
        "# NOTE: This assumes the variable 'best_elastic' was defined and trained in a previous cell.\n",
        "final_elastic_model = best_elastic\n",
        "\n",
        "# 4. Make predictions on the processed test data\n",
        "# The prediction will be in the log-transformed space (Log(1 + HotelValue))\n",
        "predictions_log = final_elastic_model.predict(X_test_processed)\n",
        "\n",
        "# 5. Reverse the transformation: exp(x) - 1\n",
        "predictions = np.expm1(predictions_log)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "predictions = np.maximum(0, predictions)\n",
        "\n",
        "# 6. Create the submission DataFrame by combining the raw IDs and the predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'HotelValue': predictions\n",
        "})\n",
        "\n",
        "# 7. Save the file in the required format\n",
        "submission_df.to_csv('submission_elastic_final.csv', index=False)\n",
        "\n",
        "print(\"\\n--- ElasticNet Submission File Created ---\")\n",
        "print(\"File Name: submission_elastic_final.csv\")\n",
        "print(\"Submission Head:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgENdxbFyJVR",
        "outputId": "50a880cf-37ba-4d79-97e1-4b7e76d88cff"
      },
      "id": "kgENdxbFyJVR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Final Prediction using Tuned ElasticNet Model...\n",
            "\n",
            "--- ElasticNet Submission File Created ---\n",
            "File Name: submission_elastic_final.csv\n",
            "Submission Head:\n",
            "     Id     HotelValue\n",
            "0   893  147852.188015\n",
            "1  1106  312108.706816\n",
            "2   414  109781.286913\n",
            "3   523  154914.193929\n",
            "4  1037  289483.130153\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlpro_env (3.11.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}